{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhGVl047QP0M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzax5630CSrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bTn-gVeqG5k"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8cG6RhfZFAW",
        "outputId": "e63f413e-924f-40bc-ff6e-e2b41fbeab39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uajmNFUDZEdp"
      },
      "outputs": [],
      "source": [
        "path='drive/My Drive/Forest Fire Dataset/Training/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KewQ6b0ncFdj"
      },
      "outputs": [],
      "source": [
        "batch_siz=32\n",
        "image_height=128\n",
        "img_width=128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WENxUzNLcjYS",
        "outputId": "f989077d-dab7-4dc4-8a1a-19071523f2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6484 files belonging to 2 classes.\n",
            "Using 5188 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "path,\n",
        "validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(image_height,img_width),\n",
        "    batch_size=batch_siz\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi9QSx5jcw9C",
        "outputId": "1025eb64-501b-4e2f-f6b2-9ab2c0a7459a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "['fire', 'nofire']\n"
          ]
        }
      ],
      "source": [
        "print(train_ds)\n",
        "print(train_ds.class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxNIEk_Jc931",
        "outputId": "496c7689-3788-4f38-e236-d9be41138e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6484 files belonging to 2 classes.\n",
            "Using 1296 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "path,\n",
        "validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(image_height,img_width),\n",
        "    batch_size=batch_siz\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWeIhzTQczLx"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE=tf.data.AUTOTUNE\n",
        "train_ds=train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds=val_ds.cache().prefetch(buffer_size=AUTOTUNE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7gYCkV3dLg-"
      },
      "outputs": [],
      "source": [
        "num_classes=2\n",
        "model=tf.keras.models.Sequential([\n",
        "\n",
        "                                  tf.keras.layers.InputLayer(input_shape=(image_height,img_width,3)),\n",
        "                                  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "\n",
        "                                  tf.keras.layers.Conv2D(16,3 ,activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "                                  tf.keras.layers.Conv2D(32,3,activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "                                  tf.keras.layers.Conv2D(64,3,activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "\n",
        "                                  tf.keras.layers.Flatten(),\n",
        "                                  tf.keras.layers.Dense(128,activation='relu'),\n",
        "                                  tf.keras.layers.Dropout(0.5),\n",
        "                                  tf.keras.layers.Dense(num_classes,activation='softmax')\n",
        "\n",
        "                                 ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmfluwzbdPHA",
        "outputId": "bc776b34-26bf-4b9c-a53c-ba9516f102c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "163/163 [==============================] - 4s 12ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.1766 - val_accuracy: 0.9730\n",
            "Epoch 2/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.1807 - val_accuracy: 0.9784\n",
            "Epoch 3/30\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1214 - val_accuracy: 0.9776\n",
            "Epoch 4/30\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.1207 - val_accuracy: 0.9776\n",
            "Epoch 5/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.2044 - val_accuracy: 0.9715\n",
            "Epoch 6/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.6192 - val_accuracy: 0.9514\n",
            "Epoch 7/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.1268 - val_accuracy: 0.9761\n",
            "Epoch 8/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1247 - val_accuracy: 0.9784\n",
            "Epoch 9/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.1436 - val_accuracy: 0.9753\n",
            "Epoch 10/30\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.2164 - val_accuracy: 0.9637\n",
            "Epoch 11/30\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.2500 - val_accuracy: 0.9653\n",
            "Epoch 12/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.2076 - val_accuracy: 0.9776\n",
            "Epoch 13/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2514 - val_accuracy: 0.9753\n",
            "Epoch 14/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.2618 - val_accuracy: 0.9745\n",
            "Epoch 15/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.1357 - val_accuracy: 0.9769\n",
            "Epoch 16/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1788 - val_accuracy: 0.9784\n",
            "Epoch 17/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.1856 - val_accuracy: 0.9784\n",
            "Epoch 18/30\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1718 - val_accuracy: 0.9776\n",
            "Epoch 19/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 8.2011e-04 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9792\n",
            "Epoch 20/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.2764 - val_accuracy: 0.9722\n",
            "Epoch 21/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.2130 - val_accuracy: 0.9730\n",
            "Epoch 22/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.2342 - val_accuracy: 0.9753\n",
            "Epoch 23/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 0.1683 - val_accuracy: 0.9745\n",
            "Epoch 24/30\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.1898 - val_accuracy: 0.9699\n",
            "Epoch 25/30\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.1751 - val_accuracy: 0.9753\n",
            "Epoch 26/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1819 - val_accuracy: 0.9745\n",
            "Epoch 27/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2115 - val_accuracy: 0.9776\n",
            "Epoch 28/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.7708e-04 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9784\n",
            "Epoch 29/30\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.2414 - val_accuracy: 0.9722\n",
            "Epoch 30/30\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.2108 - val_accuracy: 0.9699\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        "            #  loss='sparse_categorical_crossentropy',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "early_stop_back=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',min_delta=0.001,\n",
        "                                               patience=5)\n",
        "\n",
        "history=model.fit(train_ds,validation_data=val_ds,\n",
        "                 epochs=30\n",
        "                 )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpgtl30_2pL7"
      },
      "outputs": [],
      "source": [
        "#WEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OGbZ-5WgoTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5974974a-9a4a-457a-be00-4edbe1ccc6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 6ms/step - loss: 0.1522 - accuracy: 0.9769\n",
            "Accuracy 0.9768518805503845\n",
            "loss 0.15215598046779633\n"
          ]
        }
      ],
      "source": [
        "loss,acc=model.evaluate(val_ds,batch_size=batch_siz)\n",
        "print(\"Accuracy\",acc)\n",
        "print(\"loss\",loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd0_9voTgw3e"
      },
      "outputs": [],
      "source": [
        "model.save(\"drive/My Drive/fire_model_final_forweb.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vXnY8H6hB1H"
      },
      "outputs": [],
      "source": [
        "def prediction(img):\n",
        "    class_names = ['fire', 'not fire']\n",
        "    my_image = load_img(img, target_size=(image_height, img_width))\n",
        "    my_image = img_to_array(my_image)\n",
        "    my_image = np.expand_dims(my_image, 0)\n",
        "    out = np.round(model.predict(my_image)[0], 2)\n",
        "    fig = plt.figure(figsize=(7, 4))\n",
        "    plt.barh(class_names, out, color='lightgray',edgecolor='red', linewidth=1,height=0.5)\n",
        "    for index, value in enumerate(out):\n",
        "        plt.text(value/2 + 0.1, index, f\"{100*value:.2f}%\", fontweight='bold')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([0, 1], labels=class_names, fontweight='bold',fontsize=14)\n",
        "        fig.savefig('pred_img.png', bbox_inches='tight')\n",
        "    if out[0]>out[1]:\n",
        "      print(\"Fire detected\")\n",
        "    elif out[0]<out[1]:\n",
        "      print(\"No fire detected\")\n",
        "    return plt.show(),my_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-e95rcthI2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb80e86d-db57-4c72-9d71-8a554a8cf697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "Fire detected\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              " array([[[[145.,  34.,  27.],\n",
              "          [147.,  34.,  28.],\n",
              "          [148.,  35.,  27.],\n",
              "          ...,\n",
              "          [105.,  15.,  27.],\n",
              "          [109.,  19.,  29.],\n",
              "          [107.,  17.,  27.]],\n",
              " \n",
              "         [[140.,  31.,  26.],\n",
              "          [143.,  34.,  29.],\n",
              "          [146.,  35.,  28.],\n",
              "          ...,\n",
              "          [108.,  18.,  28.],\n",
              "          [103.,  15.,  27.],\n",
              "          [104.,  18.,  31.]],\n",
              " \n",
              "         [[138.,  30.,  27.],\n",
              "          [141.,  33.,  30.],\n",
              "          [143.,  34.,  29.],\n",
              "          ...,\n",
              "          [111.,  19.,  30.],\n",
              "          [102.,  16.,  29.],\n",
              "          [102.,  18.,  33.]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          ...,\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.]],\n",
              " \n",
              "         [[  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          ...,\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.]],\n",
              " \n",
              "         [[  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          ...,\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.],\n",
              "          [  0.,   0.,   0.]]]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "prediction(\"/content/98.jpg\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nvVZ-shlXDky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku0Sod74gOcJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4258f471-cff8-4dc5-f6d6-707c86c38e48"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-68cb91b6492a>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmask_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "tsend=cv2.imread(\"/content/98.jpg\")\n",
        "blur=cv2.GaussianBlur(tsend,(15,15),0)\n",
        "hsv=cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
        "lower=[18,50,50]\n",
        "upper=[35,255,255]\n",
        "lower1=np.array(lower,dtype='uint8')\n",
        "upper1=np.array(upper,dtype='uint8')\n",
        "mask=cv2.inRange(hsv,lower1,upper1)\n",
        "\n",
        "output=cv2.bitwise_and(tsend,hsv,mask=mask)\n",
        "mask_ = Image.fromarray(output)\n",
        "bbox=mask_.getbbox()\n",
        "plt.imshow(tsend)\n",
        "\n",
        "print(bbox)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgafS7y3gUqs"
      },
      "outputs": [],
      "source": [
        "  plt.imshow(blur)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEuqp5yLgVj3"
      },
      "outputs": [],
      "source": [
        "th=127\n",
        "max_v=255\n",
        "ret, o1 = cv2.threshold(output,th,max_v,cv2.THRESH_BINARY)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}